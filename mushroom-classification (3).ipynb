{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Binary Classification to Detect whether a Mushroom is Poisonous\n\n### ~Arnav Modi\n\nThe following program has been created to look at data (which is in a csv format) and based on that make predictions as to whether a mushroom is poisonous or not. The dataset has been taken from kaggle. This is the link for the dataset: [Mushroom Classification | Kaggle (safe to eat or deadly poison)](http://https://www.kaggle.com/uciml/mushroom-classification). The following are the main components of this program:\n\n* Importing the required libraries\n* Gettintg the directory of the data (CSV file)\n* About the data\n* Converting the data from a CSV format to a Pandas DataFrame\n* Visualising some features of the data using a graph\n* Converting categorial values into dummy variables\n* Splitting the data into X and y\n* Converting the Pandas DataFrame into a numpy array\n* Checking if X and y have the appropriate dimensions\n* Splitting X and y into X_train, X_test, y_train, y_test\n* Checking the dimensions of X_train, y_train, X_test, y_test\n* Creating a Sequential model\n* Viewing the model's summary\n* Visualising the layers in the model\n* Compiling the model\n* Adding EarlyStopping\n* Visualising loss and binary accuracy"},{"metadata":{},"cell_type":"markdown","source":"# Importing the required Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt  \nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom IPython.display import SVG\nfrom tensorflow.keras.utils import plot_model, model_to_dot\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Getting the directory of the data (CSV file)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# About the data\n\n* **Attribute Information:** (classes: edible=e, poisonous=p)\n\n* **cap-shape:** bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\n\n* **cap-surface:** fibrous=f,grooves=g,scaly=y,smooth=s\n\n* **cap-color:** brown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y\n\n* **bruises:** bruises=t,no=f\n\n* **odor:** almond=a,anise=l,creosote=c,fishy=y,foul=f,musty=m,none=n,pungent=p,spicy=s\n\n* **gill-attachment:** attached=a,descending=d,free=f,notched=n\n\n* **gill-spacing:** close=c,crowded=w,distant=d\n\n* **gill-size:** broad=b,narrow=n\n\n* **gill-color:** black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y\n\n* **stalk-shape:** enlarging=e,tapering=t\n\n* **stalk-root:** bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r,missing=?\n\n* **stalk-surface-above-ring:** fibrous=f,scaly=y,silky=k,smooth=s\n\n* **stalk-surface-below-ring:** fibrous=f,scaly=y,silky=k,smooth=s\n\n* **stalk-color-above-ring:** brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n\n* **stalk-color-below-ring:** brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n\n* **veil-type:** partial=p,universal=u\n\n* **veil-color:** brown=n,orange=o,white=w,yellow=y\n\n* **ring-number:** none=n,one=o,two=t\n\n* **ring-type:** cobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z\n\n* **spore-print-color:** black=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y\n\n* **population:** abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y\n\n* **habitat:** grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d"},{"metadata":{},"cell_type":"markdown","source":"# Converting the data from a CSV format to a Pandas dataframe"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_dir = \"/kaggle/input/mushroom-classification/mushrooms.csv\"\nmushroom_data = pd.read_csv(data_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mushroom_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualising some features of the data using graphs"},{"metadata":{"trusted":true},"cell_type":"code","source":"edible_count, poisonous_count = mushroom_data['class'].value_counts()\n\nfig = plt.figure(figsize = (10, 10)) \n  \nplt.bar([\"edible\", \"poisonous\"], [edible_count, poisonous_count], color = [\"blue\", \"green\"], width = 0.4) \n  \nplt.xlabel(\"Classes\") \nplt.ylabel(\"Number of Mushrooms\") \nplt.title(\"Mushrooms Categorised by Class\") \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cap_shape = mushroom_data['cap-shape'].value_counts()\n\nfig = plt.figure(figsize = (10, 10)) \n  \nplt.bar([\"bell\", \"conical\",\"convex\",\"flat\", \"knobbed\",\"sunken\"], cap_shape, color = [\"blue\", \"orange\",\"green\", \"cyan\", \"pink\", \"red\"], width = 0.4) \n  \nplt.xlabel(\"Classes\") \nplt.ylabel(\"Number of Mushrooms\") \nplt.title(\"Mushrooms Categorised by Cap Shape\") \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Converting categorical values into dummy variables\n\n### Example:\n\nIn the original dataset, there was a column called cap-shape **(bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s)**. After applying the get_dummies() method, 6 dummy variables **(cap-shape_b, cap-shape_c, cap-shape_f, cap-shape_k, cap-shape_s, cap-shape_x)** were created in place of the cap-shape column."},{"metadata":{"trusted":true},"cell_type":"code","source":"mushroom_data = pd.get_dummies(mushroom_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mushroom_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = mushroom_data.columns\ncolumns_lst = list(columns)\nfeatures = columns_lst[1:]\nprint(features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting the data into X and y\n\nX contains all the features on which the model would be trained and y contains the corresponding labels (ie. poisonous or edible)."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = mushroom_data[features]\ny = mushroom_data[\"class_p\"] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Converting the pandas DataFrame into a numpy array"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.DataFrame(X).to_numpy()\ny = pd.DataFrame(y).to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking if X and y have the appropriate dimensions"},{"metadata":{"trusted":true},"cell_type":"code","source":"examples, features = X.shape\nlabels, _ = y.shape\n\nprint(\"There are {} examples and {} features\".format(examples, features))\nprint(\"There are {} corresponding labels\".format(labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting X and y into X_train, X_test, y_train, y_test\n\nThe number of training examples would be 60% and the number of testing examples would be 40%. \n\nRandom state = 1 ensures that the method (test_train_split) returns the same results each time."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1, train_size = 0.6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking the dimensions of X_train, y_train, X_test, y_test"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_examples, training_features = X_train.shape\nlabels , _ = y_train.shape\n\nprint(\"There are {} training examples and {} training features\".format(training_examples, training_features))\nprint(\"There are {} corresponding labels for the training examples\".format(labels))\n\nprint()\n\ntesting_examples, testing_features = X_test.shape\nlabels , _ = y_test.shape\n\nprint(\"There are {} testing examples and {} testing features\".format(testing_examples, testing_features))\nprint(\"There are {} corresponding labels for the testing examples\".format(labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating a Sequential model using keras\n\nHere, batch normalization has been applied to the input layer as well as the three hidden layers  in the model. Batch normalization would reduce each value to a scale of 0 to 1, thus making sure that even deep neural networks can be trained in a short amount of time.\n\nThe dense layer performs an operation at each of the neurons in a layer. The equation used to represent this is y = wx + b. Here, y is the output, w is the weight, x is the input, and b is the bias.\n\nDropout randomly drops out a few of the inputs (which is specified by the argument). This plays a key role in preventing the model from overfitting the data to the training dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.Sequential([\n    \n    layers.BatchNormalization(input_shape = [X_train.shape[1]]),\n    \n    layers.Dense(32, activation = \"relu\"),\n    layers.BatchNormalization(),\n    layers.Dropout(0.4),\n    \n    layers.Dense(64, activation = \"relu\"),\n    layers.BatchNormalization(),\n    layers.Dropout(0.4),\n    \n    layers.Dense(128, activation = \"relu\"),\n    layers.BatchNormalization(),\n    layers.Dropout(0.4),\n    \n    \n    layers.Dense(1, activation = \"sigmoid\"),\n    \n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Viewing the model's Summary"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualising the layers in the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model, to_file='illustration.png')\nSVG(model_to_dot(model).create(prog='dot', format='svg'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compiling the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer = \"adam\",\n    loss = \"binary_crossentropy\",\n    metrics = [\"binary_accuracy\"]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Adding earlystopping to stop raining when the accuracy is not improving"},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = keras.callbacks.EarlyStopping(\n    patience = 32,\n    min_delta = 0.001,\n    restore_best_weights = True,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n    \n    X_train,\n    y_train,\n    validation_data = (X_test, y_test),\n    batch_size = 10,\n    epochs = 30,\n    callbacks = [early_stopping],\n    verbose = 2\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualising loss and binary accuracy using a graph"},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch = [i for i in range(1, len(history_df) + 1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = history_df[\"loss\"]\nval_loss = history_df[\"val_loss\"]\n\nplt.plot(epoch, loss, 'r')\nplt.plot(epoch, val_loss, 'b')\nplt.title(\"Loss vs Epoch\")\n\nplt.legend([\"loss\", \"val_loss\"], loc =\"upper right\") \n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_accuracy = history_df[\"binary_accuracy\"]\nval_binary_accuracy = history_df[\"val_binary_accuracy\"]\n\nplt.plot(epoch, binary_accuracy, 'r')\nplt.plot(epoch, val_binary_accuracy, 'b')\nplt.title(\"Binary Accuracy vs Epoch\")\n\n\nplt.legend([\"binary_accuracy\", \"val_binary_accuracy\"], loc =\"lower right\") \n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *THE END*"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}